library(languageR)
library(ggplot2)
library(dplyr)
library(carData)
carData
libary(carData)
library(carData)
###########################################################################################
###########################################################################################
install.packages("carData")
library(languageR)
library(ggplot2)
library(dplyr)
library(carData)
## We will use the dataset UN98 from the package carData.
## a) Load the package and inspect the data set
summary(carData.Un98)
## We will use the dataset UN98 from the package carData.
## a) Load the package and inspect the data set
summary(carData.UN98)
carData
library(carData)
carData
library(carData)
carData::UN98
## We will use the dataset UN98 from the package carData.
## a) Load the package and inspect the data set
summary(carData::UN98)
head(carData:UN98)
head(carData::UN98)
colnames(carData::UN98)
AsiaMale_uf
AsiaMale_uf <- subset(carData::UN98, select = c("educationMale", "lifeMale", "GDPperCapita", "economicActivityMale", "illiteracyMale", "region"))
AsiaMale_uf
filteredCarData <- carData::UN98 %>% filter(tfr == "Asia")
filteredCarData
clear
carData::UN98$tfr
colnames(carData::UN98)
carData::UN98$region
head(carData::UN98)
filteredCarData <- carData::UN98 %>% filter(region == "Asia")
filteredCarData
AsiaMale <-
carData::UN98 %>%
filter(region == "Asia" %>%)
AsiaMale <-
carData::UN98 %>%
filter(region == "Asia") %>%
subset( select = c("educationMale", "lifeMale", "GDPperCapita", "economicActivityMale", "illiteracyMale", "region"))
AsiaMale
AsiaMale <-
carData::UN98 %>%
filter(region == "Asia") %>%
subset( select = c("educationMale", "lifeMale", "GDPperCapita", "economicActivityMale", "illiteracyMale"))
AsiaMale
rm(AsiaMale_uf)
rm(filteredCarData)
## c) Let's say you're interested in whether there is a linear relationship between
## illiteracy percentage and life expectancy of males in the different countries.
## Take a look at the relationship between the two variables by
## means of a scatterplot (use the ggplot library for this).
ggplot(AsiaMale, aes(lifeMale,illiteracyMale ))+geom_point()
## e) Get the correlations between all variables in the data set using cor().
## Tell R to only include complete pairs of observations.
cor(x = AsiaMale$lifeMale, AsiaMale$illiteracyMale, use="pairwise.complete.obs")
## e) Get the correlations between all variables in the data set using cor().
## Tell R to only include complete pairs of observations.
cor(x = AsiaMale$lifeMale, y = AsiaMale$illiteracyMale, use="pairwise.complete.obs")
print(test)
test <- cor(x = AsiaMale$lifeMale, y = AsiaMale$illiteracyMale, use="pairwise.complete.obs")
print(test)
summary(test)
test <- cor(x = AsiaMale$lifeMale, y = AsiaMale$illiteracyMale, use="complete.obs")
print(test)
summary(test)
test <- cor(x = AsiaMale$lifeMale, y = AsiaMale$illiteracyMale, use="pairwise.complete.obs")
summary(test)
test <- cor(x = AsiaMale$lifeMale, y = AsiaMale$illiteracyMale, use="pairwise.complete.obs", method = "kendall")
summary(test)
test <- cor(x = AsiaMale$lifeMale, y = AsiaMale$illiteracyMale, use="pairwise.complete.obs", method = "person")
test <- cor(x = AsiaMale$lifeMale, y = AsiaMale$illiteracyMale, use="pairwise.complete.obs", method = "pearson")
summary(test)
## Tell R to only include complete pairs of observations.
test <- cor(x = AsiaMale$lifeMale, y = AsiaMale$illiteracyMale, use="pairwise.complete.obs", method = "spearman")
summary(test)
correlation <- cor(y = AsiaMale$lifeMale, x = AsiaMale$illiteracyMale, use="pairwise.complete.obs")
summary(correlation)
correlation <- cor(x = AsiaMale$lifeMale, y = AsiaMale$illiteracyMale, use="pairwise.complete.obs")
#correlation <- cor(y = AsiaMale$lifeMale, x = AsiaMale$illiteracyMale, use="pairwise.complete.obs")
summary(correlation)
## g) Is the correlation between life expectancy and GDPperCapita significant? Use cor.test()
cor.test(x = AsiaMale$lifeMale, y = AsiaMale$GDPperCapita)
## h) Calculate the Spearman rank correlation between life expectancy and GDPperCapita and compare
## it to the pearson correlation calculated above.
cor(x = AsiaMale$lifeMale, AsiaMale$GDPperCapita, method = "spearman")
## h) Calculate the Spearman rank correlation between life expectancy and GDPperCapita and compare
## it to the pearson correlation calculated above.
cor(x = AsiaMale$lifeMale, AsiaMale$GDPperCapita, method = "spearman", use = "pairwise.complete.obs")
diff <- abs(cor.test(x = AsiaMale$lifeMale, y = AsiaMale$GDPperCapita),
cor(x = AsiaMale$lifeMale, AsiaMale$GDPperCapita, method = "spearman", use = "pairwise.complete.obs"))
diff <- abs(cor.test(x = AsiaMale$lifeMale, y = AsiaMale$GDPperCapita)-
cor(x = AsiaMale$lifeMale, AsiaMale$GDPperCapita, method = "spearman", use = "pairwise.complete.obs"))
## i) make a scatterplot of this relationship.
ggplot(AsiaMale, aes(lifeMale, GDPperCapita))+geom_point()
cor(AsiaMale)
cor(AsiaMale, use="pairwise.complete.obs")
## i) make a scatterplot of this relationship.
ggplot(AsiaMale, aes(lifeMale, GDPperCapita))+geom_point()
install.packages("ggpubr")
library(ggpubr) # for the correlation plots
## i) make a scatterplot of this relationship.
ggplot(AsiaMale, aes(lifeMale, GDPperCapita))+geom_point() + stat_cor(method = "spearman", cor.coef.name = "rho")
###########################################################################################
###########################################################################################
install.packages("psych")
library(psych)
## k) Using the function paired.r from the package psych, compare the correlations between life expectancy
##  and economic activity on the one hand, and life expectancy and illiteracy on the other hand.
##  Hint: the degrees of freedom in a correlation test are equal to N-2
r_le_ea <- cov(AsiaMale$lifeMale, AsiaMale$economicActivityMale, use ="pairwise.complete.obs")
r_le_ea <-
cov(AsiaMale$lifeMale, AsiaMale$economicActivityMale, use = "pairwise.complete.obs") / (sd(AsiaMale$lifeMale, na.rm = TRUE) * sd(AsiaMale$economicActivityMale, na.rm = TRUE))
r_le_ea <-
cov(AsiaMale$lifeMale, AsiaMale$economicActivityMale, use = "pairwise.complete.obs") / (sd(AsiaMale$lifeMale, na.rm = TRUE) * sd(AsiaMale$economicActivityMale, na.rm = TRUE))
r_le_i <- cov(AsiaMale$lifeMale, AsiaMale$illiteracyMale, use = "pairwise.complete.obs") / (sd(AsiaMale$lifeMale, na.rm = TRUE) * sd(AsiaMale$illiteracyMale, na.rm = TRUE))
le_VS_ea <- paired.r(xy = r_le_ea, r_le_i, n = length(AsiaMale$lifeMale))
le_VS_ea
## m) What would be the result, if the two variables would be independent?
paired.r(xy = r_le_ea, r_le_i, 0.8,n = length(AsiaMale$lifeMale))
lifeExpByGDPt <- lm(lifeMale ~ GDPt, data = AsiaMale)
## We will use the same dataset as above, but first scale the GDP to be in the unit of
## thousand dollars
AsiaMale$GDPt = AsiaMale$GDPperCapita / 1000
lifeExpByGDPt <- lm(lifeMale ~ GDPt, data = AsiaMale)
summary(lifeExpByGDPt)
lifeExpByIll <- lm(lifeMale ~ illiteracyMale, data = AsiaMale)
summary(lifeExpByIll)
## e) Plot lifeMale by illiteracyMale and add a regression line to your plot
ggplot(AsiaMale, aes(lifeMale, illiteracyMale)) + geom_point()+geom_smooth(method="lm", formula =lifeMale~ illiteracyMale )
ggplot(AsiaMale, aes(lifeMale, illiteracyMale)) +
geom_point() +
geom_line(color="red", data = lifeExpByIll )
ggplot(AsiaMale, aes(lifeMale, illiteracyMale)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
ggplot(AsiaMale, aes(lifeMale, illiteracyMale)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)+
geom_abline(slope=coef(lifeExpByIll)[["lifeMale"]], intercept =coef(lifeExpByIll)[["(Intercept)"]] )
ggplot(AsiaMale, aes(lifeMale, illiteracyMale)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)+
geom_abline(slope=coef(lifeExpByIll)[["illiteracyMale"]], intercept =coef(lifeExpByIll)[["(Intercept)"]] )
ggplot(AsiaMale, aes(lifeMale, illiteracyMale)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
## a) Run a multiple regression model with illiteracyMale and GDPt as predictors
## General form:
## "modelname <- lm(outcome ~ predictor1+predictor2+.., data = dataFrame, na.action = an action)"
## "summary(modelname)"
lifeExpByGDPt_Ill <- lm(lifeMale~ illiteracyMale + GDPt, data = AsiaMale, na-action = na.exclude)
## a) Run a multiple regression model with illiteracyMale and GDPt as predictors
## General form:
## "modelname <- lm(outcome ~ predictor1+predictor2+.., data = dataFrame, na.action = an action)"
## "summary(modelname)"
lifeExpByGDPt_Ill <- lm(lifeMale~ illiteracyMale + GDPt, data = AsiaMale, na.action = na.exclude)
summary(lifeExpByGDPt_Ill)
summary(lifeExpByGDPt)
summary(lifeExpByIll)
summary(lifeExpByGDPt_Ill)
## d) Look up the GDP and illiteracyMale for United.States and Brazil in the original data set (UN98)
illiteracyMale <- carData::UN98 %>% filter(region == "United.States" | region == "Brazil") %>% select("illiteracyMale")
illiteracyMale
illiteracyMale <- carData::UN98 %>% filter(region == "United.States" | region == "Brazil") %>% subset(select = c("illiteracyMale"))
illiteracyMale
illiteracyMale <-
carData::UN98 %>% filter(region == "United.States" ||
region == "Brazil") %>% subset(select = c("illiteracyMale"))
illiteracyMale
## h) Look at the summary and report what changed in comparison to both linmod and poimod.
summary(mixedpoi)
mixedpoi <-
glmer (coffee ~ sleep + mood + temperature
+ (1 | subj),
family = poisson,
data = coffeedat)
### Stats with R Exercise sheet 9
##################################################################################
# Week 11: Model Families and Logistic Regression
##################################################################################
## This exercise sheet contains the exercises that you will need to complete and
## submit by 23:55 on Sunday, January 8. Write the code below the questions.
## If you need to provide a written answer, comment this out using a hashtag (#).
## Submit your homework via cms
## Please write below your (and your teammates) name, matriculation number.
## Name:
## Matriculation number:
## Name:
## Matriculation number:
## Name:
## Matriculation number:
##################################################################################
##################################################################################
# The following line of code clears your workspace:
rm(list = ls())
library(rstudioapi)
# Set the path to source file location:
setwd(dirname(getActiveDocumentContext()$path))
##################################################################################
## Exercise 1: Logistic regression
##################################################################################
require(carData)
require(dplyr)
require(lme4)
require(ggplot2)
## Look at the dataset TitanicSurvival from the carData package.
## a) Build a simple logistic regression model that models the probability of survival
##    (binary) based on sex (categorical) and  passengerClass (categorical) without
##    an interaction and store it in mSurv.
##    You have to use the glm() function and specify the family correctly.
summary(TitanicSurvival)
mSurv <-
glm(survived ~ sex + passengerClass,
family = binomial(logit),
data = TitanicSurvival)
## b) Look at the summary. What group does the intercept correspond to?
summary(mSurv)
## c) Were men more likely to survive than women? Is the effect significant?
# No, men were less likely to survive (2.5 time LESS likely then women), this effect is significant (p-value < 0.005).
## d) Imagine two passengers: Rose (female, 1st class passenger) and Jack (male, 3rd class passenger).
##    Calculate their expected survival on the logit scale (i.e. the scale of the model)
##    either by hand or using predict() with a new data.frame
predict(mSurv, data.frame(
sex = c("female", "male"),
passengerClass = c("1st", "3rd")
))
# odds rose =  2.11
# odds jack = -2.13
## e) Transform your results from d to the probability scale, using the formula given on the slides.
##    You can check your calculation by asserting the probabilities lie in the 0-1 range.
##    For whom does the model predict the higher probability of survival?
# rose -> p(odds_rose) = 2.11 / (1 + 2.11) = 0.678
# jack -> p(odds_jack) = -2.13 / (1 - 2.13) = 1,885 (must be wrong!)
##################################################################################
## Exercise 2: Generalized Linear Mixed effect models
##################################################################################
## In this exercise, we will again look at connections between coffee consumption
## and sleep (among others). The data set "coffee.csv" contains data from 10 students,
## who reported on 10 randomly chosen days of the year:
##  sleep:  how many hours of sleep they had in the previous night
##  mood:   how happy they felt on a scale from 1 (very unhappy)-10 (extremely happy)
##  coffee: how many cups of coffee they had on that day
## In addition, the maximal temperature on that day was entered into the dataset.
## Our research hypotheses are:
## students consume more coffee, when they are tired
## students consume more coffee, if they don't feel well
## students consume more coffee, when it is cold outside
## a) Download the data set from cms and read it in, store it in a variable called: coffeedat
coffeedat <- read.csv(file = "coffee.csv")
## b) Plot the number of consumed cups of coffee in three individual scatterplots
##    by sleep, mood, and temperature.
##    You can use geom_jitter() to get a nicer plot
# could not get it to work without a new library
library(ggpubr)
base_p <- ggplot(coffeedat, aes(y = coffee))
ggarrange(
base_p + geom_jitter(aes(x = sleep)),
base_p + geom_jitter(aes(x = mood)),
base_p + geom_jitter(aes(x = temperature)),
ncol = 3
)
## c) Can you detect an obvious relationship in any of the plots?
# yes:
# increased values for sleep and mood decrease the average coffee consumption.
# increaseed values for temperature increase the average coffee consumption.
## d) Fit a simple linear regression model with all three predictors and store it in linmod
linmod <- lm(coffee ~ sleep + mood + temperature, data = coffeedat)
## e) Fit a generalized linear model with the appropriate family
##    (hint: coffee is a count variable) and store it in poimod
poimod <-
glm(coffee ~ sleep + mood + temperature,
family = poisson ,
data = coffeedat)
## f) Look at the two summaries of the models and write what changed?
summary(linmod)
summary(poimod)
# poimod has different values for al coefficients, this is because if the family.
# Poisson uses logarithmic scaling, this means that the coefficient values are in the logarithmic scale as well.
# The model got more confident in addition (all p-values got smaller).
## g) In fact, we have repeated measures in our design, so refit the model
##    including a random intercept for subject using glmer() with the correct
##    family specification and store it in mixedpoi
mixedpoi <-
glmer (coffee ~ sleep + mood + temperature
+ (1 | subj),
family = poisson,
data = coffeedat)
## h) Look at the summary and report what changed in comparison to both linmod and poimod.
summary(mixedpoi)
# The p-values got smaller again, thus the model is more confident
## i) Finally, to make it complete, also run a mixed model using the gaussian family and store it in mixedlin
# glmer with family = gaussian is the same as the below
mixedlin <-  lmer (coffee ~ sleep + mood + temperature
+ (1 | subj),
data = coffeedat)
## j) Compare the AIC for all four models. Which one has the best fit?
AIC(linmod, poimod, mixedpoi, mixedlin)
# mixedpoi is the best fit, as it has the smallest AIC-value.
## k) And which model is conceptually the appropriate one? Explain why.
# mixedpoi as well:
# 1) The model needs a random effect (and intercept), because a persons response to the factors (sleep, mood, temp.) vary from person to person.
# 2) The Poission distribution is the best fit as discussed in the lecture.
## l) Finally, report on the effects of interest in light of our research hypotheses
##    specified above for the model you chose in k)
summary(mixedpoi)
mixedpoi
### Stats with R Exercise sheet 8
##############################################################################
# Week 10: Linear Mixed Effects Models
##############################################################################
## This exercise sheet contains the exercises that you will need to complete and
## submit by 23:55 on Sunday, January 8. Write the code below the questions.
## If you need to provide a written answer, comment this out using a hashtag (#).
## Submit your homework via cms
## Name: Chaahat Jain
## Matriculation number: 7025099
## Name: Denis Krieger
## Matriculation Number: 7021772
## Name: Eric Minas
## Matriculation Number: 2568884
###############################################################################
###############################################################################
# The following line of code clears your workspace:
rm(list = ls())
library(languageR)
library(lme4)
library(lattice)
library(Matrix)
library(ggplot2)
library(dplyr)
###############################################################################
### 1. Linear mixed model for chicken growth
###############################################################################
## a) We will first look at the dataset ChickWeight, which is already
##    loaded in base R. Check out the help page of the data set to understand
##    how the data was collected and look at the summary.
help(ChickWeight)
summary(ChickWeight)
## b) Let's plot the data.
##    1) Group the data by Diet and Time. Use a function summarySE()
##       from Rmisc library to get the mean and se of weight.
##       Assign resulting dataset to aggData.
library(Rmisc)
? summarySE()
aggData <-
summarySE(
data = ChickWeight,
measurevar = "weight",
groupvars = c("Diet", "Time")
)
##    2) Create a line plot of aggData, plotting weight on the y axis, time on the x-axis and color by Diet.
##       Also add errorbars (mean+/-1.96*se)
ggplot(aggData, aes(Time, weight, color = Diet)) +
geom_line() +
geom_errorbar(ymin = aggData$weight - 1.96 * aggData$se,
ymax = aggData$weight + 1.96 * aggData$se)
## c) The above plot ignored that the data comes from a fixed set of chicks. Let's look at individual growth
##    by coloring by Chick instead of by Diet, but faceting by Diet (side by side). You have to use ChickWeight
##    instead of aggData here! Also you don't need error bars, because you are not plotting the mean, but the
##    actual data
ggplot(ChickWeight, aes(Time, weight, color = Chick)) +
geom_line() +
facet_wrap(ChickWeight$Diet)
## d) What do you observe, looking at c?
# Diet 1 has a lot of outliers,
# Diet 2 is more concentrated with only 2 extreme outliers
# Diet 3 is more concentrated than diet 2
# Diet 4 is the most concentrated diet.
# Overall Diet 3 seems to be the best perfoming (highest lowpoint and highest high-point)
## e) We want to investigate whether the type of diet has an effect on the chick's growth, i.e. we are
##    looking for an interaction between time after birth and the diet type. Before running the model,
##    specify:
##    1) What fixed effect(s) do you enter into the model?
# time, diet and their interaction.
# We choose time, because it changes predictably for each chick.
# We choose diet since it is constant for each chick,
# The interaction is needed, because we want to check whether the time and diet influence the weight. If that is the case then diet works.
##    2) what random effect(s) should be included to account for the repeated measures structure of the data?
# intercept for each chick, because we have different starting points and we need to make it comparable across each chick.
##    3) In addition to random intercept(s), which random slope(s) should you add to get a maximal model?
# Random slope is time because for every chick, we are keeping track of values at different points of time.
## f) Run the model you specified in e) using lmer() and assign it to chickmod
chickmod <-
lmer(weight ~  Time * Diet +
(1 + Time | Chick), data = ChickWeight)
## g) Rerun the model leaving out the interaction between Time and Diet and assign it to chicknull
chicknull <-
lmer(weight ~ Time + Diet +
(1 + Time | Chick), data = ChickWeight)
## h) compare the two models using the anova() function, which performs a likelihood ratio test
anova(chickmod, chicknull)
## i) Report the p-value (from h) and the conclusion with respect to the research hypothesis
# p-value << 0.005, I can therefore expect that the likelyhood ratio is significant and chickmod and chicknull contain equal data
## j) The following code creates a plot of all chick specific intercepts and slopes. What do you see?
print(dotplot(ranef(chickmod, condVar = TRUE),  scales = list(x = list(relation = 'free')))[["Chick"]])
# The slopes (vertical lines) seem quite equal for all chickens and only the intercepts are different.
# If that is actually the case, then the diet has no significant effect on the weight of the chicken after the observed time.
#####################################################
### 2. Random effect structures
#####################################################
## a) Let's return to the lexdec data set from Sheet 4 and suppose, we want to look
##    at effects of the word type of the previously presented word (each subject saw a
##    different randomized sequence) and effects of the complexity of the word itself, while
##    taking into account the dependence between data points collected on the same word and from the same subject.
##    Which of the following models has a maximal random effect structure given the experimental design?
##    Motivate your choice.
m1 = lmer(RT ~ PrevType + Complex +
(PrevType | Subject) +
(Complex | Word),
lexdec)
m2 = lmer(RT ~ PrevType + Complex +
(PrevType + Complex | Subject) +
(PrevType | Word),
lexdec)
m3 = lmer(RT ~ PrevType + Complex +
(PrevType + Complex | Subject) +
(PrevType + Complex | Word),
lexdec)
m4 = lmer(RT ~ PrevType + Complex +
(Complex | Subject) +
(PrevType | Word),
lexdec)
m5 = lmer(RT ~ PrevType + Complex +
(PrevType + Complex | Subject) +
(1 | Word),
lexdec)
# m5 is the best approach:
# it takes both the subject and the item into account
# it takes the (random-) effect of the previous word type and complexity for the subject (=participant) into account.
# it takes the (random-) effect of the word into account.
# there is no need to add prevType/complexity for the word, as the word itself does not change due to those factors.
# Therefore the intersections suffices.
## b) You want to relate students' performance in the advanced algebra course in a summer school in Saarbrücken
##    to their final math grade in school. The summer school course has 200 participants, coming from 8 different
##    partner Universities from all over Germany. These 200 participants were randomly split into 10 tutorial groups,
##    where each tutorial was held by a different tutor.
##    Given the design of your study, what random effects should you add to the following model:
##    NOTE: We accept only the answers with explanations!
## lmer(advancedalgebrascore ~ mathGrade, someData)
# We should include the tutor as a random effect, as the effectiveness of the tutors teaching is depending on the tutors skill,
# as well as the participants (i.e. students that only look at their phone will have worse grades than those that pay attention)
# If the data contains the german state the student got thier final math grade in, we can also take that into account,
# because not all states teach the same solving techniques /  talk about the same things.
m1
summary(m1)
