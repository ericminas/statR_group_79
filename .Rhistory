chi$expected
chi$observed
## d. What are the expected frequencies? Do we need to look at expected or
##    observed frequencies?
chi$expected
# We look at the observed frequencies as that corresponds to our data
chi$observed
## f. Assume we don't have the possibility to sample more students. Which test do
##    you have to run instead? How does it work roughly? Perform a suitable test
# we should run Fisher's exact test, because the table we have is 3x2 (too big for X^2) and the variables are independent.
# We create all tables that can be produced by changing the values in rows and columns, with the constraint that all totals must stay the same
# Then we determine the sum of probabilities of the tables which were more extreme than the original table
# if the sum is less than 0.05, we reject the null-hypothesis
fisher.test(table(clean$drink, clean$sleepProblem))
## a) What is the chance in a single roll of earning a point?
p <- 2/6
## b) Please calculate the probability of getting exactly 3 points.
##    Calculate this using the dbinom() function.
dbinom(3,size = 20,prob=p)
## c) Next please calculate the probability of getting less than 6 points
pbinom(5, 20, p, lower.tail = TRUE) # 29.7%
## d) What is the difference between density function and distribution function?
## d) What is the difference between density function and distribution function?
# distribution function is used for discrete random variables
#########################################
#########################################
## Exercise 4
##  In order to better understand the relationship between sleeping problems and
##  In order to better understand the relationship between sleeping problems and
##  consumed drinks, we set up a better controlled experiment:
##  In order to better understand the relationship between sleeping problems and
##  consumed drinks, we set up a better controlled experiment:
##  For two weeks, students are asked to drink mostly coffee and are then asked
##  In order to better understand the relationship between sleeping problems and
##  consumed drinks, we set up a better controlled experiment:
##  For two weeks, students are asked to drink mostly coffee and are then asked
##  whether they encountered sleep problems. For another two weeks, the same students
## a) Can you use the ChiSquare test in this situation? Explain and motivate
## a) Can you use the ChiSquare test in this situation? Explain and motivate
##  your answer
## a) Can you use the ChiSquare test in this situation? Explain and motivate
##  your answer
# No, this will not work as our observations are not independent.
## b) Is there an alternative test you could use? Why would this be appropriate?
## b) Is there an alternative test you could use? Why would this be appropriate?
# We can use McNemar's Test, as here we are concerned only with the people who have changed sleepProblems after switching drinks.
## b) Is there an alternative test you could use? Why would this be appropriate?
# We can use McNemar's Test, as here we are concerned only with the people who have changed sleepProblems after switching drinks.
## b) Is there an alternative test you could use? Why would this be appropriate?
# We can use McNemar's Test, as here we are concerned only with the people who have changed sleepProblems after switching drinks.
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(lex, aes(x = Freq)) + geom_bar() + geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
library(lsr)
library(tidyr)
library(dplyr)
# install.packages("ggplot2")
library(ggplot2)
library(languageR)
## a. Create the dataset lex, which is a copy of lexdec, but only includes the columns
##  indicated above
lex <- subset(lexdec, TRUE, c("Subject", "Complex", "RT", "Sex", "Frequency"))
## Run the following line to prepare the dataset for later steps:
lex = lex %>% mutate(Freq = as.factor(ifelse(Frequency > 4.75, "high", "low")))
## Before we start testing, we want to get an impression of the data and create a barplot of
## the mean by Freq, including error bars that show the 95% CI.
## Here, we define a function to calculate the standard error, which is needed for the CI:
## (just execute the next line, as you will need the function in 2.)
se = function(x){sd(x)/sqrt(length(x))}
## d. To start, we need to summarize the data. Use the functions group_by() in combination with
##  summarise(). In particular, you need to group by Freq and get the mean as well as the
##  se of RT. Store the result to summaryByFreq
##  You will find examples of how the summarizing can be done here:
##  https://datacarpentry.org/R-genomics/04-dplyr.html#split-apply-combine_data_analysis_and_the_summarize()_function
summaryByFreq <- lex %>% group_by(Freq) %>% summarize(m = mean(RT), serr = se(RT))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(lex, aes(x = Freq)) + geom_bar() + geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
View(summaryByFreq)
## g. The barplot always starts at zero, which makes the portion of the graph, we are most
##  interested in (i.e. the spread of the error bars) hard to perceive. As an alternative,
##  construct a line plot of the same data, again including error bars.
##  Hint: if you get a complaint, try to add group = 1 to your aes
ggplot(summaryByFreq, aes(x = Freq, y = serr)) + geom_line(aes(group = 1)) + geom_point() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
## g. The barplot always starts at zero, which makes the portion of the graph, we are most
##  interested in (i.e. the spread of the error bars) hard to perceive. As an alternative,
##  construct a line plot of the same data, again including error bars.
##  Hint: if you get a complaint, try to add group = 1 to your aes
ggplot(summaryByFreq, aes(x = Freq, y = m)) + geom_line(aes(group = 1)) + geom_point() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(summaryByFreq, aes(x = Freq)) + geom_bar() + geom_errorbar(aes(ymin = m - serr, ymax = m + serr))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(summaryByFreq, aes(x = Freq, y = m)) + geom_bar() + geom_errorbar(aes(ymin = m - serr, ymax = m + serr))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(lex, aes(x = Freq)) + geom_bar() + geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
## i. Let's go back to the original data frame "lex".
##  Now that you've taken a look at the data, you want to get into the stats.
##  You want to compute a t-test for the average RT for low vs high frequency nouns.
##  Why can't you compute a t-test on the data as they are now?
##  Hint: Which assumption is violated?
str(lex)
## j. We need to restructure the data to only one observation (average RT) per subject
##  and low/high condition (Freq). We will again use group_by and summarize, but
##  this time we have to group by Subject and Freq, while we only need the mean to be
##  stored, not the se. Assign the result to bySubj
bySubj <- lex %>% group_by(Freq, Subject) %>% summarize(m = mean(RT))
View(bySubj)
?geom_histogram
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(y = m)) + geom_histogram()
?geom_histogram
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_histogram()
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_histogram(binwidth = 0.8, alpha = 0.5)
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_histogram(binwidth = 0.8, alpha = 0.5, position = "identity")
?geom_histogram
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_histogram(binwidth = 0.8, alpha = 0.5, position = "dodge")
## l. Display the same data in density plots.
d <- density(bySubj$m)
plot(d)
## l. Display the same data in density plots.
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_density()
## l. Display the same data in density plots.
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_density(alpha = 0.5)
## n. Create boxplots of the mean RT in bySubj by Freq
ggplot(bySubj, aes(x = Freq, y = m)) + geom_boxplot()
## p. Compute the t-test you specified above
hd <- subset(bySubj, Freq == "high")
View(hd)
ld <- subset(bySubj, Freq == "low")
t.test(hd$m, ld$m, paired = TRUE)
t.test(ld$m, hd$m, paired = TRUE)
## r. Compute the effect size using Cohen's D.
cohensD(ld$m, hd$m, method = "paired")
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean$RT) %>% spread()
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean(RT)) %>% spread()
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean(RT)) %>% spread(var = var(RT))
?spread
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean(RT)) %>% spread(key = Subject, value = m)
View(wide)
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean(RT)) %>% spread(key = Complex, value = m)
View(wide)
## b. Compute a t-test on the wide format data - note that for wide-format
##  data you need to use a different syntax inside t.test()
t.test(wide$complex - wide$simplex, var.equal=TRUE)
str(lex)
t.test(m ~ Sex, bySubjSex)
## b. Use again group_by and summarize to obtain by subject means of RT, but
## this time with regard to Sex and assign it to bySubjSex
## Perform the t-test you decided for.
bySubjSex <- lex %>% group_by(Subject, Sex) %>% summarize(m = mean(RT))
t.test(m ~ Sex, bySubjSex)
## d. Choose an appropriate plot to visualize the result
ggplot(bySubjSex, aes(x = Sex, y = m)) + geom_boxplot()
library(lsr)
library(tidyr)
library(dplyr)
# install.packages("ggplot2")
library(ggplot2)
library(languageR)
## a. Create the dataset lex, which is a copy of lexdec, but only includes the columns
##  indicated above
lex <- subset(lexdec, TRUE, c("Subject", "Complex", "RT", "Sex", "Frequency"))
str(lex)
## Run the following line to prepare the dataset for later steps:
lex = lex %>% mutate(Freq = as.factor(ifelse(Frequency > 4.75, "high", "low")))
## Before we start testing, we want to get an impression of the data and create a barplot of
## the mean by Freq, including error bars that show the 95% CI.
## Here, we define a function to calculate the standard error, which is needed for the CI:
## (just execute the next line, as you will need the function in 2.)
se = function(x){sd(x)/sqrt(length(x))}
## d. To start, we need to summarize the data. Use the functions group_by() in combination with
##  summarise(). In particular, you need to group by Freq and get the mean as well as the
##  se of RT. Store the result to summaryByFreq
##  You will find examples of how the summarizing can be done here:
##  https://datacarpentry.org/R-genomics/04-dplyr.html#split-apply-combine_data_analysis_and_the_summarize()_function
summaryByFreq <- lex %>% group_by(Freq) %>% summarize(m = mean(RT), serr = se(RT))
View(summaryByFreq)
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(lex, aes(x = Freq)) + geom_bar() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(lex, aes(x = Freq)) + geom_bar() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - 1.96*serr, ymax = m + 1.96*serr))
View(summaryByFreq)
View(summaryByFreq)
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(summaryByFreq, aes(x = Freq)) + geom_bar() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - 1.96*serr, ymax = m + 1.96*serr))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(summaryByFreq, aes(x = Freq, y = m)) + geom_bar() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - 1.96*serr, ymax = m + 1.96*serr))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(summaryByFreq, aes(x = Freq)) + geom_bar() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - 1.96*serr, ymax = m + 1.96*serr))
## g. The barplot always starts at zero, which makes the portion of the graph, we are most
##  interested in (i.e. the spread of the error bars) hard to perceive. As an alternative,
##  construct a line plot of the same data, again including error bars.
##  Hint: if you get a complaint, try to add group = 1 to your aes
ggplot(summaryByFreq, aes(x = Freq, y = m)) + geom_line(aes(group = 1)) + geom_point() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
## g. The barplot always starts at zero, which makes the portion of the graph, we are most
##  interested in (i.e. the spread of the error bars) hard to perceive. As an alternative,
##  construct a line plot of the same data, again including error bars.
##  Hint: if you get a complaint, try to add group = 1 to your aes
ggplot(summaryByFreq, aes(x = Freq, y = m)) + geom_line(aes(group = 1)) + geom_point() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - 1.96*serr, ymax = m + 1.96*serr))
## i. Let's go back to the original data frame "lex".
##  Now that you've taken a look at the data, you want to get into the stats.
##  You want to compute a t-test for the average RT for low vs high frequency nouns.
##  Why can't you compute a t-test on the data as they are now?
##  Hint: Which assumption is violated?
str(lex)
View(lex)
plot(lex$RT)
?qqplot
qqnorm(lex$RT)
?qqplot
qqplot(lex$RT)
qqplot(y = lex$RT)
qqPlot(y = lex$RT)
??qqPlot
qqnorm(y = lex$RT)
histogram(lex$RT)
hist(lex$RT)
# RT is not normal (slightly right skewed)
lex
## j. We need to restructure the data to only one observation (average RT) per subject
##  and low/high condition (Freq). We will again use group_by and summarize, but
##  this time we have to group by Subject and Freq, while we only need the mean to be
##  stored, not the se. Assign the result to bySubj
bySubj <- lex %>% group_by(Freq, Subject) %>% summarize(m = mean(RT))
## j. We need to restructure the data to only one observation (average RT) per subject
##  and low/high condition (Freq). We will again use group_by and summarize, but
##  this time we have to group by Subject and Freq, while we only need the mean to be
##  stored, not the se. Assign the result to bySubj
bySubj <- lex %>% group_by(Subject, Freq) %>% summarize(m = mean(RT))
View(bySubj)
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_histogram(binwidth = 0.08, alpha = 0.5, position = "dodge")
## l. Display the same data in density plots.
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_density(alpha = 0.5)
ggplot(bySubj, aes(x = m, fill = Freq)) +
geom_histogram(position = position_dodge(), binwidth = 0.08)
ggplot(bySubj, aes(x = mean, fill = Freq)) +
geom_density()
ggplot(bySubj, aes(x = m, fill = Freq)) +
geom_density()
## l. Display the same data in density plots.
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_density(alpha = 0.5)
## n. Create boxplots of the mean RT in bySubj by Freq
ggplot(bySubj, aes(x = Freq, y = m)) + geom_boxplot()
## p. Compute the t-test you specified above
hd <- subset(bySubj, Freq == "high")
ld <- subset(bySubj, Freq == "low")
t.test(ld$m, hd$m)
## r. Compute the effect size using Cohen's D.
cohensD(ld$m, hd$m)
?cohensD
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean(RT)) %>% spread(key = Complex, value = m)
View(wide)
?melt
## b. Compute a t-test on the wide format data - note that for wide-format
##  data you need to use a different syntax inside t.test()
t.test(wide$complex - wide$simplex, var.equal=TRUE)
## b. Compute a t-test on the wide format data - note that for wide-format
##  data you need to use a different syntax inside t.test()
t.test(wide$complex - wide$simplex)
## b. Compute a t-test on the wide format data - note that for wide-format
##  data you need to use a different syntax inside t.test()
t.test(wide$complex, wide$simplex)
View(lex)
## b. Use again group_by and summarize to obtain by subject means of RT, but
## this time with regard to Sex and assign it to bySubjSex
## Perform the t-test you decided for.
bySubjSex <- lex %>% group_by(Subject, Sex) %>% summarize(m = mean(RT))
View(bySubjSex)
t.test(m ~ Sex, bySubjSex)
## d. Choose an appropriate plot to visualize the result
ggplot(bySubjSex, aes(x = Sex, y = m)) + geom_boxplot()
## a. Generate 10 random samples from a normal distribution with mean 20 and sd 8 and save it in a variable
##  called "tutor1_grades"
tutor1_grades <- rnorm(10, 20, 8)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(10, 28, 10)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- cbind(tutor1_grades, tutor2_grades)
View(score)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- rbind(tutor1_grades, tutor2_grades)
View(score)
View(score)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",10),rep("tutor2",10))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- cbind(tutor, score)
View(data_frame)
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data_frame(cbind(tutor, score))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.df(cbind(tutor, score))
?as
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
?independentSamplesTTest
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
str(data_frame)
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
## In this exercise we will again use simulation to explore the independent samples t-test
## with different samples.
## We will take a similar example as discussed in the lecture. A class has two tutors, and we want
## to find out which tutor is better by comparing the performance of the students in the final
## exam by tutor group. First set a seed to make sure your results can be reproduced
bleh = function(sample, mean1, sdev1, mean2, sdev2){
set.seed(9273)
tutor1_grades <- rnorm(sample, mean1, sdev1)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(sample, mean2, sdev2)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",sample),rep("tutor2",sample))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
}
bleh(10, 20, 8, 28, 10)
set.seed(9273)
bleh = function(sample, mean1, sdev1, mean2, sdev2){
tutor1_grades <- rnorm(sample, mean1, sdev1)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(sample, mean2, sdev2)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",sample),rep("tutor2",sample))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
}
## a. Generate 10 random samples from a normal distribution with mean 20 and sd 8 and save it in a variable
##  called "tutor1_grades"
tutor1_grades <- rnorm(10, 20, 8)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(10, 28, 10)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",10),rep("tutor2",10))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
bleh(10, 20, 8, 28, 10)
bleh = function(sample, mean1, sdev1, mean2, sdev2){
set.seed(9273)
tutor1_grades <- rnorm(sample, mean1, sdev1)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(sample, mean2, sdev2)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",sample),rep("tutor2",sample))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
}
bleh(10, 20, 8, 28, 10)
tutor1_grades <- rnorm(sample, mean1, sdev1)
expe = function(sample, mean1, sdev1, mean2, sdev2){
set.seed(9273)
tutor1_grades <- rnorm(sample, mean1, sdev1)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(sample, mean2, sdev2)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",sample),rep("tutor2",sample))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
}
expe(10, 20, 8, 28, 10)
## g. Repeat the whole experiment you performed above with different sample size
##  (the number of samples drawn from each tutor group). How big does your sample need to be in order
##  for the t test to be significant when keeping mean and sd constant?
## make sure to set the seed again before you run your code to be able to reproduce results
expe(20, 20, 8, 28, 10)
## g. Repeat the whole experiment you performed above with different sample size
##  (the number of samples drawn from each tutor group). How big does your sample need to be in order
##  for the t test to be significant when keeping mean and sd constant?
## make sure to set the seed again before you run your code to be able to reproduce results
expe(40, 20, 8, 28, 10)
## g. Repeat the whole experiment you performed above with different sample size
##  (the number of samples drawn from each tutor group). How big does your sample need to be in order
##  for the t test to be significant when keeping mean and sd constant?
## make sure to set the seed again before you run your code to be able to reproduce results
expe(25, 20, 8, 28, 10)
expe(30, 20, 8, 28, 10)
## h.	repeat the whole experiment you performed in a-f with different means.
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 8, 40, 10)
## h.	repeat the whole experiment you performed in a-f with different means.
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 8, 30, 10)
## h.	repeat the whole experiment you performed in a-f with different means.
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 8, 20, 10)
## h.	repeat the whole experiment you performed in a-f with different means.
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 8, 30, 10)
expe(25, 20, 8, 40, 10)
expe(25, 20, 5, 40, 10)
expe(25, 20, 5, 20, 10)
## i.	Now, vary the standard deviation, keeping means and sample size constant!
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 5, 20, 15)
expe(25, 20, 5, 20, 20)
expe(25, 20, 5, 20, 25)
expe(25, 20, 5, 20, 30)
expe(25, 20, 5, 20, 50)
expe(25, 20, 2, 20, 30)
