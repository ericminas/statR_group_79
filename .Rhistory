## c. get a summary of the dataset
summary(data)
str(data)
head(data)
## d. the variable sleepProblem should be a numerical variable and have 0 for no Problem
##    and 1 for sleep problems.
##    Make sure that this is the case
str(data)#
data$sleepProblem <- ifelse(data$sleepProblem == "no", "0", data$sleepProblem)
data$sleepProblem <- ifelse(data$sleepProblem == "yes", "1", data$sleepProblem)
data$sleepProblem <- ifelse(data$sleepProblem == "11", "1", data$sleepProblem)
data$sleepProblem <- as.numeric(data$sleepProblem)
## e. how many students encounter sleep problems?
table(data$sleepProblem) # 25 students encounter sleep problems
## f. how many different drinks do students name? (transform the variable into a
## factor first)
data$drink <- as.factor(data$drink)
table(data$drink) # there are 3 different drinks
## g. collapse factor levels which were spelled wrong. Make sure you first handle
## case and whitespace incongruencies, before you fix individual misspellings
data$drink <- gsub(" ", "", str_to_lower(data$drink))
table(data$drink)
data$drink <- str_replace(data$drink, "tee", "tea")
table(data$drink)
data$drink <- str_replace(data$drink, "tee", "tea")
data$drink <- str_replace(data$drink, "koffee", "coffee")
data$drink <- str_replace(data$drink, "coffe", "coffee")
data$drink <- str_replace(data$drink, "cofee", "coffee")
table(data$drink)
data$drink <- str_replace(data$drink, "coffeee", "coffee")
table(data$drink)
## You realize that most students had multiple exams in the week from Feb 22 to
## Feb 26. As students had to learn a lot and were possibly worried, they might
## misjudge or exaggerate their sleep problems as occurring "regularly"
## We want to exclude all data that was collected between and including Feb 15
## and Feb 26!
str(data)
## You realize that most students had multiple exams in the week from Feb 22 to
## Feb 26. As students had to learn a lot and were possibly worried, they might
## misjudge or exaggerate their sleep problems as occurring "regularly"
## We want to exclude all data that was collected between and including Feb 15
## and Feb 26!
data$date <- as.Date(data$date)
?subset
clean_data <- data %>% filter(date < "2021-02-22" || date > "2021-02-26")
View(clean_data)
str(data)
lb <- as.Date("2021-02-22")
ub <- as,Date("2021-02-26")
ub <- as.Date("2021-02-26")
clean_data <- data %>% filter(date < lb || date > ub)
clean_data <- data %>% filter(date < lb)
clean_data <- data %>% filter(date < lb | date > ub)
View(clean_data)
View(clean_data)
View(data)
View(data)
View(data)
View(data)
data <- read.csv('insomnia22.csv')
View(data)
View(data)
data$sleepProblem <- ifelse(data$sleepProblem == "no", "0", data$sleepProblem)
data$sleepProblem <- ifelse(data$sleepProblem == "yes", "1", data$sleepProblem)
data$sleepProblem <- ifelse(data$sleepProblem == "11", "1", data$sleepProblem)
data$sleepProblem <- as.numeric(data$sleepProblem)
## e. how many students encounter sleep problems?
table(data$sleepProblem) # 25 students encounter sleep problems
data$drink <- as.factor(data$drink)
table(data$drink) # there are 3 different drinks
## g. collapse factor levels which were spelled wrong. Make sure you first handle
## case and whitespace incongruencies, before you fix individual misspellings
data$drink <- gsub(" ", "", str_to_lower(data$drink))
data$drink <- str_replace(data$drink, "tee", "tea")
data$drink <- str_replace(data$drink, "koffee", "coffee")
data$drink <- str_replace(data$drink, "coffe", "coffee")
data$drink <- str_replace(data$drink, "cofee", "coffee")
data$drink <- str_replace(data$drink, "coffeee", "coffee")
table(data$drink)
## and Feb 26!
data$date <- as.Date(data$date)
str(data)
lb <- as.Date("2021-02-22")
ub <- as.Date("2021-02-26")
clean_data <- data %>% filter(date < lb | date > ub)
?chisq.test
## b. conduct a chisquare test to test this hypothesis using the function chisq.test()
##    and assign the result to chi
chi <- chisq.test(clean$drink, clean$sleepProblem)
clean <- data %>% filter(date < lb | date > ub)
## b. conduct a chisquare test to test this hypothesis using the function chisq.test()
##    and assign the result to chi
chi <- chisq.test(clean$drink, clean$sleepProblem)
View(chi)
## d. What are the expected frequencies? Do we need to look at expected or
##    observed frequencies?
chi$expected
# We look at the observed frequencies as that corresponds to our data
chi$observed
?fisher.test
fisher.test(clean$drink, clean$sleepProblem)
## a) What is the chance in a single roll of earning a point?
p <- 2/6
?dbinom
## b) Please calculate the probability of getting exactly 3 points.
##    Calculate this using the dbinom() function.
dbinom(size = 20, prob = p)
## b) Please calculate the probability of getting exactly 3 points.
##    Calculate this using the dbinom() function.
dbinom(3, size = 20, prob = p)
## c) Next please calculate the probability of getting less than 6 points
dbinom(6, 20, p, lower.tail = FALSE)
?pbinom
## c) Next please calculate the probability of getting less than 6 points
pbinom(6, 20, p, lower.tail = FALSE)
## c) Next please calculate the probability of getting less than 6 points
pbinom(6, 20, p, lower.tail = TRUE) # 52%
## a) Can you use the ChiSquare test in this situation? Explain and motivate
##  your answer
# No, this will not work as our observations are not independent.
clean
## a) Can you use the ChiSquare test in this situation? Explain and motivate
##  your answer
# No, this will not work as our observations are not independent.
hist(clean)
## a) Can you use the ChiSquare test in this situation? Explain and motivate
##  your answer
# No, this will not work as our observations are not independent.
hist(clean$drink)
## a) Can you use the ChiSquare test in this situation? Explain and motivate
##  your answer
# No, this will not work as our observations are not independent.
hist(as.numeric(clean$drink))
## d. What are the expected frequencies? Do we need to look at expected or
##    observed frequencies?
chi$expected
clean <- data %>% filter(date < lb | date > ub)
install.packages("stringr")
install.packages("dplyr")
install.packages("tidyr")
install.packages("forcats")
library(stringr)
library(dplyr)
library(tidyr)
library(forcats)
## b. read in the data
getwd()
data <- read.csv('insomnia22.csv')
#
## c. get a summary of the dataset
summary(data)
str(data)
head(data)
## d. the variable sleepProblem should be a numerical variable and have 0 for no Problem
##    and 1 for sleep problems.
##    Make sure that this is the case
str(data)#
data$sleepProblem <- ifelse(data$sleepProblem == "no", "0", data$sleepProblem)
data$sleepProblem <- ifelse(data$sleepProblem == "yes", "1", data$sleepProblem)
data$sleepProblem <- ifelse(data$sleepProblem == "11", "1", data$sleepProblem)
data$sleepProblem <- as.numeric(data$sleepProblem)
## e. how many students encounter sleep problems?
table(data$sleepProblem) # 25 students encounter sleep problems
## f. how many different drinks do students name? (transform the variable into a
## factor first)
data$drink <- as.factor(data$drink)
table(data$drink) # there are 3 different drinks
## g. collapse factor levels which were spelled wrong. Make sure you first handle
## case and whitespace incongruencies, before you fix individual misspellings
data$drink <- gsub(" ", "", str_to_lower(data$drink))
data$drink <- str_replace(data$drink, "tee", "tea")
data$drink <- str_replace(data$drink, "koffee", "coffee")
data$drink <- str_replace(data$drink, "coffe", "coffee")
data$drink <- str_replace(data$drink, "cofee", "coffee")
data$drink <- str_replace(data$drink, "coffeee", "coffee")
table(data$drink)
## You realize that most students had multiple exams in the week from Feb 22 to
## Feb 26. As students had to learn a lot and were possibly worried, they might
## misjudge or exaggerate their sleep problems as occurring "regularly"
## We want to exclude all data that was collected between and including Feb 15
## and Feb 26!
## h.  First show how many data points will be concerned, you need to transform
##     the date column to a Date object first!
data$date <- as.Date(data$date)
str(data)
## i. Now filter out this part of the data and assign the result to clean
lb <- as.Date("2021-02-22")
ub <- as.Date("2021-02-26")
clean <- data %>% filter(date < lb | date > ub)
## b. conduct a chisquare test to test this hypothesis using the function chisq.test()
##    and assign the result to chi
chi <- chisq.test(clean$drink, clean$sleepProblem)
## d. What are the expected frequencies? Do we need to look at expected or
##    observed frequencies?
chi$expected
# We look at the observed frequencies as that corresponds to our data
chi$observed
insomnia <- read.csv("insomnia22.csv", header = TRUE)
## c. get a summary of the dataset
summary(insomnia)
## d. the variable sleepProblem should be a numerical variable and have 0 for no Problem
##    and 1 for sleep problems.
##    Make sure that this is the case
# num of entires that have neither 1 or 0 = 3
insomnia %>%
filter(sleepProblem != 0 & sleepProblem != 1)
insomnia$sleepProblem[insomnia$sleepProblem == "yes"] <- 1
insomnia$sleepProblem[insomnia$sleepProblem == "no"] <- 0
insomnia$sleepProblem[insomnia$sleepProblem == 11] <- 1
## e. how many students encounter sleep problems?
# -> 25 students have sleep problems
insomnia %>% filter(sleepProblem == 1) %>% count(sleepProblem)
## f. how many different drinks do students name? (transform the variable into a
## factor first)
insomnia$drink <- as.factor(insomnia$drink)
# 3 distinct levels, 10 levels overall
levels(insomnia$drink)
## g. collapse factor levels which were spelled wrong. Make sure you first handle
## case and whitespace incongruencies, before you fix individual misspellings)
# trim + case cleanup
insomnia <- insomnia %>%
mutate(drink = str_trim(drink)) %>%
mutate(drink = str_to_lower(drink))
# collapsing
insomnia <- insomnia %>%
mutate(drink = fct_collapse(drink, coffee = c("cofee", "coffe", "koffee"))) %>%
mutate(drink = fct_collapse(drink, tea = c("tee")))
# checking
insomnia$drink <- as.factor(insomnia$drink)
levels(insomnia$drink)
## You realize that most students had multiple exams in the week from Feb 22 to
## Feb 26. As students had to learn a lot and were possibly worried, they might
## misjudge or exaggerate their sleep problems as occurring "regularly"
## We want to exclude all data that was collected between and including Feb 15
## and Feb 26!
## h.  First show how many data points will be concerned, you need to transform
##     the date column to a Date object first!
insomnia$date <- as.Date(insomnia$date)
affected <- insomnia %>%
filter(date >= "2021-02-15" & date <= "2021-02-26")
count(affected) # -> 10 students
## i. Now filter out this part of the data and assign the result to clean
clean <- insomnia %>%
filter(date < "2021-02-15" | date > "2021-02-26")
## b. conduct a chisquare test to test this hypothesis using the function chisq.test()
##    and assign the result to chi
chi <- chisq.test(clean$drink, clean$sleepProblem)
# We look at the observed frequencies as that corresponds to our data
chi$observed
## b. conduct a chisquare test to test this hypothesis using the function chisq.test()
##    and assign the result to chi
chi <- chisq.test(clean$drink, clean$sleepProblem)
## d. What are the expected frequencies? Do we need to look at expected or
##    observed frequencies?
chi$expected
# We look at the observed frequencies as that corresponds to our data
chi$observed
fisher.test(clean$drink, clean$sleepProblem)
## a) What is the chance in a single roll of earning a point?
p <- 2/6
## c) Next please calculate the probability of getting less than 6 points
pbinom(5, 20, p, lower.tail = TRUE) # 48%
# We can use McNemar's Test, as here we are concerned only with the people who have changed sleepProblems after switching drinks.
## a. Load the libraries stringr, dplyr, tidyr and forcats
#install.packages("stringr")
library(stringr)
#install.packages("dplyr")
library(dplyr)
#install.packages("tidyr")
library(tidyr)
#install.packages("forcats")
library(forcats)
## b. read in the data
# setwd("/home/l1/Desktop/statR_group_79/")
insomnia <- read.csv("insomnia22.csv", header = TRUE)
## c. get a summary of the dataset
summary(insomnia)
## d. the variable sleepProblem should be a numerical variable and have 0 for no Problem
##    and 1 for sleep problems.
##    Make sure that this is the case
# num of entires that have neither 1 or 0 = 3
insomnia %>%
filter(sleepProblem != 0 & sleepProblem != 1)
insomnia$sleepProblem[insomnia$sleepProblem == "yes"] <- 1
insomnia$sleepProblem[insomnia$sleepProblem == "no"] <- 0
insomnia$sleepProblem[insomnia$sleepProblem == 11] <- 1
## e. how many students encounter sleep problems?
# -> 25 students have sleep problems
insomnia %>% filter(sleepProblem == 1) %>% count(sleepProblem)
## f. how many different drinks do students name? (transform the variable into a
## factor first)
insomnia$drink <- as.factor(insomnia$drink)
# 3 distinct levels, 10 levels overall
levels(insomnia$drink)
# trim + case cleanup
insomnia <- insomnia %>%
mutate(drink = str_trim(drink)) %>%
mutate(drink = str_to_lower(drink))
# collapsing
insomnia <- insomnia %>%
mutate(drink = fct_collapse(drink, coffee = c("cofee", "coffe", "koffee"))) %>%
mutate(drink = fct_collapse(drink, tea = c("tee")))
# checking
insomnia$drink <- as.factor(insomnia$drink)
levels(insomnia$drink)
## You realize that most students had multiple exams in the week from Feb 22 to
## Feb 26. As students had to learn a lot and were possibly worried, they might
## misjudge or exaggerate their sleep problems as occurring "regularly"
## We want to exclude all data that was collected between and including Feb 15
## and Feb 26!
## h.  First show how many data points will be concerned, you need to transform
##     the date column to a Date object first!
insomnia$date <- as.Date(insomnia$date)
affected <- insomnia %>%
filter(date >= "2021-02-15" & date <= "2021-02-26")
count(affected) # -> 10 students
## i. Now filter out this part of the data and assign the result to clean
clean <- insomnia %>%
filter(date < "2021-02-15" | date > "2021-02-26")
## b. conduct a chisquare test to test this hypothesis using the function chisq.test()
##    and assign the result to chi
chi <- chisq.test(clean$drink, clean$sleepProblem)
chi
## c. the last call produced a warning. To understand why this warning arises, look
##    at observed and expected frequencies of chi
chi$expected
chi$observed
## d. What are the expected frequencies? Do we need to look at expected or
##    observed frequencies?
chi$expected
# We look at the observed frequencies as that corresponds to our data
chi$observed
## f. Assume we don't have the possibility to sample more students. Which test do
##    you have to run instead? How does it work roughly? Perform a suitable test
# we should run Fisher's exact test, because the table we have is 3x2 (too big for X^2) and the variables are independent.
# We create all tables that can be produced by changing the values in rows and columns, with the constraint that all totals must stay the same
# Then we determine the sum of probabilities of the tables which were more extreme than the original table
# if the sum is less than 0.05, we reject the null-hypothesis
fisher.test(table(clean$drink, clean$sleepProblem))
## a) What is the chance in a single roll of earning a point?
p <- 2/6
## b) Please calculate the probability of getting exactly 3 points.
##    Calculate this using the dbinom() function.
dbinom(3,size = 20,prob=p)
## c) Next please calculate the probability of getting less than 6 points
pbinom(5, 20, p, lower.tail = TRUE) # 29.7%
## d) What is the difference between density function and distribution function?
## d) What is the difference between density function and distribution function?
# distribution function is used for discrete random variables
#########################################
#########################################
## Exercise 4
##  In order to better understand the relationship between sleeping problems and
##  In order to better understand the relationship between sleeping problems and
##  consumed drinks, we set up a better controlled experiment:
##  In order to better understand the relationship between sleeping problems and
##  consumed drinks, we set up a better controlled experiment:
##  For two weeks, students are asked to drink mostly coffee and are then asked
##  In order to better understand the relationship between sleeping problems and
##  consumed drinks, we set up a better controlled experiment:
##  For two weeks, students are asked to drink mostly coffee and are then asked
##  whether they encountered sleep problems. For another two weeks, the same students
## a) Can you use the ChiSquare test in this situation? Explain and motivate
## a) Can you use the ChiSquare test in this situation? Explain and motivate
##  your answer
## a) Can you use the ChiSquare test in this situation? Explain and motivate
##  your answer
# No, this will not work as our observations are not independent.
## b) Is there an alternative test you could use? Why would this be appropriate?
## b) Is there an alternative test you could use? Why would this be appropriate?
# We can use McNemar's Test, as here we are concerned only with the people who have changed sleepProblems after switching drinks.
## b) Is there an alternative test you could use? Why would this be appropriate?
# We can use McNemar's Test, as here we are concerned only with the people who have changed sleepProblems after switching drinks.
## b) Is there an alternative test you could use? Why would this be appropriate?
# We can use McNemar's Test, as here we are concerned only with the people who have changed sleepProblems after switching drinks.
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(lex, aes(x = Freq)) + geom_bar() + geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
library(lsr)
library(tidyr)
library(dplyr)
# install.packages("ggplot2")
library(ggplot2)
library(languageR)
## a. Create the dataset lex, which is a copy of lexdec, but only includes the columns
##  indicated above
lex <- subset(lexdec, TRUE, c("Subject", "Complex", "RT", "Sex", "Frequency"))
## Run the following line to prepare the dataset for later steps:
lex = lex %>% mutate(Freq = as.factor(ifelse(Frequency > 4.75, "high", "low")))
## Before we start testing, we want to get an impression of the data and create a barplot of
## the mean by Freq, including error bars that show the 95% CI.
## Here, we define a function to calculate the standard error, which is needed for the CI:
## (just execute the next line, as you will need the function in 2.)
se = function(x){sd(x)/sqrt(length(x))}
## d. To start, we need to summarize the data. Use the functions group_by() in combination with
##  summarise(). In particular, you need to group by Freq and get the mean as well as the
##  se of RT. Store the result to summaryByFreq
##  You will find examples of how the summarizing can be done here:
##  https://datacarpentry.org/R-genomics/04-dplyr.html#split-apply-combine_data_analysis_and_the_summarize()_function
summaryByFreq <- lex %>% group_by(Freq) %>% summarize(m = mean(RT), serr = se(RT))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(lex, aes(x = Freq)) + geom_bar() + geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
View(summaryByFreq)
## g. The barplot always starts at zero, which makes the portion of the graph, we are most
##  interested in (i.e. the spread of the error bars) hard to perceive. As an alternative,
##  construct a line plot of the same data, again including error bars.
##  Hint: if you get a complaint, try to add group = 1 to your aes
ggplot(summaryByFreq, aes(x = Freq, y = serr)) + geom_line(aes(group = 1)) + geom_point() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
## g. The barplot always starts at zero, which makes the portion of the graph, we are most
##  interested in (i.e. the spread of the error bars) hard to perceive. As an alternative,
##  construct a line plot of the same data, again including error bars.
##  Hint: if you get a complaint, try to add group = 1 to your aes
ggplot(summaryByFreq, aes(x = Freq, y = m)) + geom_line(aes(group = 1)) + geom_point() +
geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(summaryByFreq, aes(x = Freq)) + geom_bar() + geom_errorbar(aes(ymin = m - serr, ymax = m + serr))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(summaryByFreq, aes(x = Freq, y = m)) + geom_bar() + geom_errorbar(aes(ymin = m - serr, ymax = m + serr))
## f. Now use summaryByFreq to create the barplot with error bars denoting the 95% CI
##  (i.e. mean +/-1.96 * se)
ggplot(lex, aes(x = Freq)) + geom_bar() + geom_errorbar(data = summaryByFreq, aes(ymin = m - serr, ymax = m + serr))
## i. Let's go back to the original data frame "lex".
##  Now that you've taken a look at the data, you want to get into the stats.
##  You want to compute a t-test for the average RT for low vs high frequency nouns.
##  Why can't you compute a t-test on the data as they are now?
##  Hint: Which assumption is violated?
str(lex)
## j. We need to restructure the data to only one observation (average RT) per subject
##  and low/high condition (Freq). We will again use group_by and summarize, but
##  this time we have to group by Subject and Freq, while we only need the mean to be
##  stored, not the se. Assign the result to bySubj
bySubj <- lex %>% group_by(Freq, Subject) %>% summarize(m = mean(RT))
View(bySubj)
?geom_histogram
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(y = m)) + geom_histogram()
?geom_histogram
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_histogram()
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_histogram(binwidth = 0.8, alpha = 0.5)
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_histogram(binwidth = 0.8, alpha = 0.5, position = "identity")
?geom_histogram
## k. Create histograms of the RT data in bySubj depending on the frequency category
##  and display them side by side. Set the binwidth to 0.08
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_histogram(binwidth = 0.8, alpha = 0.5, position = "dodge")
## l. Display the same data in density plots.
d <- density(bySubj$m)
plot(d)
## l. Display the same data in density plots.
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_density()
## l. Display the same data in density plots.
ggplot(bySubj, aes(x = m, fill = Freq)) + geom_density(alpha = 0.5)
## n. Create boxplots of the mean RT in bySubj by Freq
ggplot(bySubj, aes(x = Freq, y = m)) + geom_boxplot()
## p. Compute the t-test you specified above
hd <- subset(bySubj, Freq == "high")
View(hd)
ld <- subset(bySubj, Freq == "low")
t.test(hd$m, ld$m, paired = TRUE)
t.test(ld$m, hd$m, paired = TRUE)
## r. Compute the effect size using Cohen's D.
cohensD(ld$m, hd$m, method = "paired")
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean$RT) %>% spread()
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean(RT)) %>% spread()
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean(RT)) %>% spread(var = var(RT))
?spread
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean(RT)) %>% spread(key = Subject, value = m)
View(wide)
## a. Again, summarize the dataset to obtain the mean RT by "Subject" and "Complex" and transform
##  the dataset to a wide format.
##  In addition to group_by() and summarize(), you will need the function spread().
##  Assign the result to wide
wide <- lex %>% group_by(Subject, Complex) %>% summarize(m = mean(RT)) %>% spread(key = Complex, value = m)
View(wide)
## b. Compute a t-test on the wide format data - note that for wide-format
##  data you need to use a different syntax inside t.test()
t.test(wide$complex - wide$simplex, var.equal=TRUE)
str(lex)
t.test(m ~ Sex, bySubjSex)
## b. Use again group_by and summarize to obtain by subject means of RT, but
## this time with regard to Sex and assign it to bySubjSex
## Perform the t-test you decided for.
bySubjSex <- lex %>% group_by(Subject, Sex) %>% summarize(m = mean(RT))
t.test(m ~ Sex, bySubjSex)
## d. Choose an appropriate plot to visualize the result
ggplot(bySubjSex, aes(x = Sex, y = m)) + geom_boxplot()
