tutor = c(rep("tutor1",sample),rep("tutor2",sample))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
}
bleh(10, 20, 8, 28, 10)
set.seed(9273)
bleh = function(sample, mean1, sdev1, mean2, sdev2){
tutor1_grades <- rnorm(sample, mean1, sdev1)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(sample, mean2, sdev2)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",sample),rep("tutor2",sample))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
}
## a. Generate 10 random samples from a normal distribution with mean 20 and sd 8 and save it in a variable
##  called "tutor1_grades"
tutor1_grades <- rnorm(10, 20, 8)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(10, 28, 10)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",10),rep("tutor2",10))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
bleh(10, 20, 8, 28, 10)
bleh = function(sample, mean1, sdev1, mean2, sdev2){
set.seed(9273)
tutor1_grades <- rnorm(sample, mean1, sdev1)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(sample, mean2, sdev2)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",sample),rep("tutor2",sample))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
}
bleh(10, 20, 8, 28, 10)
tutor1_grades <- rnorm(sample, mean1, sdev1)
expe = function(sample, mean1, sdev1, mean2, sdev2){
set.seed(9273)
tutor1_grades <- rnorm(sample, mean1, sdev1)
## b. Now we generate our second sample of size 10 ("tutor2_grades), this time for tutor 2
##  and with mean 28 and sd 10
tutor2_grades <- rnorm(sample, mean2, sdev2)
## c. Combine the two samples and store the result into one vector called "score" (it should
##    first show all scores from tutor1 followed by the scores of tutor2)
score <- append(tutor1_grades, tutor2_grades)
## d. Create a vector called tutor indicating which tutor the score belongs to: it should show
##   "tutor1" 10 times followed by "tutor2" 10 times
tutor = c(rep("tutor1",sample),rep("tutor2",sample))
## e. Create a data frame named "data_frame" having 2 columns "tutor", "score" created above.
data_frame <- as.data.frame(cbind(tutor, score))
data_frame$score <- as.numeric(data_frame$score)
str(data_frame)
## f. run the independent samples TTest (independentSamplesTTest) and formulate the findings as discussed
###  in the lecture.
independentSamplesTTest(score ~ tutor, data = data_frame)
}
expe(10, 20, 8, 28, 10)
## g. Repeat the whole experiment you performed above with different sample size
##  (the number of samples drawn from each tutor group). How big does your sample need to be in order
##  for the t test to be significant when keeping mean and sd constant?
## make sure to set the seed again before you run your code to be able to reproduce results
expe(20, 20, 8, 28, 10)
## g. Repeat the whole experiment you performed above with different sample size
##  (the number of samples drawn from each tutor group). How big does your sample need to be in order
##  for the t test to be significant when keeping mean and sd constant?
## make sure to set the seed again before you run your code to be able to reproduce results
expe(40, 20, 8, 28, 10)
## g. Repeat the whole experiment you performed above with different sample size
##  (the number of samples drawn from each tutor group). How big does your sample need to be in order
##  for the t test to be significant when keeping mean and sd constant?
## make sure to set the seed again before you run your code to be able to reproduce results
expe(25, 20, 8, 28, 10)
expe(30, 20, 8, 28, 10)
## h.	repeat the whole experiment you performed in a-f with different means.
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 8, 40, 10)
## h.	repeat the whole experiment you performed in a-f with different means.
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 8, 30, 10)
## h.	repeat the whole experiment you performed in a-f with different means.
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 8, 20, 10)
## h.	repeat the whole experiment you performed in a-f with different means.
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 8, 30, 10)
expe(25, 20, 8, 40, 10)
expe(25, 20, 5, 40, 10)
expe(25, 20, 5, 20, 10)
## i.	Now, vary the standard deviation, keeping means and sample size constant!
##   What do you find? When is the test more likely to come out significant?
expe(25, 20, 5, 20, 15)
expe(25, 20, 5, 20, 20)
expe(25, 20, 5, 20, 25)
expe(25, 20, 5, 20, 30)
expe(25, 20, 5, 20, 50)
expe(25, 20, 2, 20, 30)
## We will use the dataset UN98 from the package carData.
## a) Load the package and inspect the data set
# install.packages("carData")
UN98
library(carData)
library(languageR)
library(ggplot2)
library(dplyr)
library(carData)
## We will use the dataset UN98 from the package carData.
## a) Load the package and inspect the data set
# install.packages("carData")
UN98
## We will use the dataset UN98 from the package carData.
## a) Load the package and inspect the data set
# install.packages("carData")
head(UN98)
str(UN98)
summary(UN98)
## b) create the dataset AsiaMale, containing the variables educationMale lifeMale GDPperCapita
##    economicActivityMale and illiteracyMale and the subset of Asian countries.
AsiaMale <- subset(UN98, region == "Asia", c("educationMale", "lifeMale", "GDPperCapita", "economicActivityMale", "illiteracyMale"))
View(AsiaMale)
## c) Let's say you're interested in whether there is a linear relationship between
## illiteracy percentage and life expectancy of males in the different countries.
## Take a look at the relationship between the two variables by
## means of a scatterplot (use the ggplot library for this).
ggplot(AsiaMale, aes(illieracyMale,lifeMale))
## c) Let's say you're interested in whether there is a linear relationship between
## illiteracy percentage and life expectancy of males in the different countries.
## Take a look at the relationship between the two variables by
## means of a scatterplot (use the ggplot library for this).
ggplot(AsiaMale, aes(illiteracyMale,lifeMale)) + geom_point()
?cor
## e) Get the correlations between all variables in the data set using cor().
## Tell R to only include complete pairs of observations.
cor(AsiaMale$lifeMale, AsiaMale$illiteracyMale, use = "complete.obs")
## e) Get the correlations between all variables in the data set using cor().
## Tell R to only include complete pairs of observations.
cor(AsiaMale, use = "complete.obs")
?cor.test
## g) Is the correlation between life expectancy and GDPperCapita significant? Use cor.test()
cor.test(AsiaMale$GDPperCapita, AsiaMale$lifeMale)
## h) Calculate the Spearman rank correlation between life expectancy and GDPperCapita and compare
## it to the pearson correlation calculated above.
cor.test(AsiaMale$GDPperCapita, AsiaMale$lifeMale, method = "spearman")
## i) make a scatterplot of this relationship.
ggplot(AsiaMale, aes(GDPperCapita,lifeMale)) + geom_point()
## k) Using the function paired.r from the package psych, compare the correlations between life expectancy
##  and economic activity on the one hand, and life expectancy and illiteracy on the other hand.
##  Hint: the degrees of freedom in a correlation test are equal to N-2
library(psych)
## k) Using the function paired.r from the package psych, compare the correlations between life expectancy
##  and economic activity on the one hand, and life expectancy and illiteracy on the other hand.
##  Hint: the degrees of freedom in a correlation test are equal to N-2
install.packages("psych")
library(psych)
?paired.r
paired.r(cor(AsiaMale$lifeMale, AsiaMale$economicActivityMale), cor(AsiaMale$lifeMale, AsiaMale$illiteracyMale))
paired.r(cor(AsiaMale$lifeMale, AsiaMale$economicActivityMale), cor(AsiaMale$lifeMale, AsiaMale$illiteracyMale),
n = length(AsiaMale$lifeMale))
paired.r(cor(AsiaMale$lifeMale, AsiaMale$economicActivityMale, use = "pairwise.complete.obs"),
cor(AsiaMale$lifeMale, AsiaMale$illiteracyMale, use = "pairwise.complete.obs"),
n = length(AsiaMale$lifeMale))
## e) Get the correlations between all variables in the data set using cor().
## Tell R to only include complete pairs of observations.
cor(AsiaMale, use = "pairwise.complete.obs")
## g) Is the correlation between life expectancy and GDPperCapita significant? Use cor.test()
cor.test(AsiaMale$GDPperCapita, AsiaMale$lifeMale)
paired.r(cor(AsiaMale$lifeMale, AsiaMale$economicActivityMale, use = "pairwise.complete.obs"),
cor(AsiaMale$lifeMale, AsiaMale$illiteracyMale, use = "pairwise.complete.obs"),
n = length(AsiaMale$lifeMale))
## a) Run a regression model of life expectancy by GDPt and look at the summary.
## General form:
## "modelname <- lm(outcome ~ predictor, data = dataFrame)"
## "summary(modelname)"
## We will use the same dataset as above, but first scale the GDP to be in the unit of
## thousand dollars
AsiaMale$GDPt = AsiaMale$GDPperCapita/1000
GDPLife <- lm(lifeMale ~ GDPt, data = AsiaMale)
## b) Interpret the model from a. What do intercept and the coefficient of GDPt tell you?
GDPLife
## c) What about the model fit: What proportion of the total variance is explained by your model?
coefficients(GDPLife)
## c) What about the model fit: What proportion of the total variance is explained by your model?
var(GDPLife)
## c) What about the model fit: What proportion of the total variance is explained by your model?
glance(GDPLife)
## c) What about the model fit: What proportion of the total variance is explained by your model?
GDPLife %>%
# Get the model-level details
glance() %>%
# Pull out r.squared
pull(r.squared)
## c) What about the model fit: What proportion of the total variance is explained by your model?
install.packages("broom")
library(broom)
GDPLife %>%
# Get the model-level details
glance() %>%
# Pull out r.squared
pull(r.squared)
## d) Now let's turn to the relationship between life expectancy and illiteracy.  Run the regression and
# interpret.
IlliLife <- lm(lifeMale ~ illiteracyMale, data = AsiaMale)
IlliLife
## e) Plot lifeMale by illiteracyMale and add a regression line to your plot
ggplot(AsiaMale, aes(illiteracyMale,lifeMale)) + geom_point() +
geom_smooth(IlliLife)
geom_smooth(aes(IlliLife)
## e) Plot lifeMale by illiteracyMale and add a regression line to your plot
ggplot(AsiaMale, aes(illiteracyMale,lifeMale)) + geom_point() +
## e) Plot lifeMale by illiteracyMale and add a regression line to your plot
ggplot(AsiaMale, aes(lifeMale, illiteracyMale)) +
geom_point() +
geom_smooth(method = "lm", se = FALSE)
?lm
## a) Run a multiple regression model with illiteracyMale and GDPt as predictors
## General form:
## "modelname <- lm(outcome ~ predictor1+predictor2+.., data = dataFrame, na.action = an action)"
## "summary(modelname)"
GDPIlliLife <- lm(lifeMale ~ illiteracyMale + GDPt, data = AsiaMale, na.action = na.omit)
## b) Interpret the model: what do intercept and the 2 coefficients tell you? What about significance?
GDPIlliLife
summary(GDPIlliLife)
GDPLife %>%
# Get the model-level details
glance() %>%
# Pull out r.squared
pull(r.squared)
summary(GDPLife)
## b) Interpret the model: what do intercept and the 2 coefficients tell you? What about significance?
summary(GDPIlliLife)
View(UN98)
summary(UN98)
head(UN98)
## d) Look up the GDP and illiteracyMale for United.States and Brazil in the original data set (UN98)
US <- UN98 %>% filter(region == "United.States" |
region == "Brazil") %>% subset(select = c("illiteracyMale"))
View(US)
## d) Look up the GDP and illiteracyMale for United.States and Brazil in the original data set (UN98)
US <- UN98[, "United.States"]
## d) Look up the GDP and illiteracyMale for United.States and Brazil in the original data set (UN98)
US <- UN98["United.States", ]
View(US)
## d) Look up the GDP and illiteracyMale for United.States and Brazil in the original data set (UN98)
US <- UN98["United.States", c("illiteracyMale", "GDP")]
## d) Look up the GDP and illiteracyMale for United.States and Brazil in the original data set (UN98)
US <- UN98["United.States", c(12, 9)]
View(US)
Brazil <- UN98["Brazil", c(12, 9)]
## b) Interpret the model: what do intercept and the 2 coefficients tell you? What about significance?
summary(GDPIlliLife)
coefficients(GDPIlliLife)
coefficients(GDPIlliLife)[1]
## e) Using the model from 3a:  What is the predicted life expectancy for United.States and Brazil?
##  Calculate "by hand", i.e. do not use predict() and show your calculation. Don't forget to divide
##  the GDPperCapita by 1000 first!
USPrec <- coefficients(GDPIlliLife)[1] + coefficients(GDPIlliLife)[2]*US$illiteracyMale +
coefficients(GDPIlliLife)[3]*US$GDPperCapita/1000
BrazilPrec <- coefficients(GDPIlliLife)[1] + coefficients(GDPIlliLife)[2]*Brazil$illiteracyMale +
coefficients(GDPIlliLife)[3]*Brazil$GDPperCapita/1000
## f) Run an additional model of life expectancy for the AsiaMale data set including also economicActivityMale
GDPIlliLife <- lm(lifeMale ~ illiteracyMale + GDPt + economicActivityMale, data = AsiaMale, na.action = na.omit)
## f) Run an additional model of life expectancy for the AsiaMale data set including also economicActivityMale
GDPIlliEcoLife <- lm(lifeMale ~ illiteracyMale + GDPt + economicActivityMale, data = AsiaMale, na.action = na.omit)
## g) Do you think inclusion of economicActivity into the model is a good idea?
summary(GDPIlliEcoLife)
## a) Run a multiple regression model with illiteracyMale and GDPt as predictors
## General form:
## "modelname <- lm(outcome ~ predictor1+predictor2+.., data = dataFrame, na.action = an action)"
## "summary(modelname)"
GDPIlliLife <- lm(lifeMale ~ illiteracyMale + GDPt, data = AsiaMale, na.action = na.omit)
library(carData)
## b) create the dataset AsiaMale, containing the variables educationMale lifeMale GDPperCapita
##    economicActivityMale and illiteracyMale and the subset of Asian countries.
AsiaMale <- subset(UN98, region == "Asia", c("educationMale", "lifeMale", "GDPperCapita", "economicActivityMale", "illiteracyMale"))
## c) Let's say you're interested in whether there is a linear relationship between
## illiteracy percentage and life expectancy of males in the different countries.
## Take a look at the relationship between the two variables by
## means of a scatterplot (use the ggplot library for this).
ggplot(AsiaMale, aes(illiteracyMale,lifeMale)) + geom_point()
library(languageR)
library(ggplot2)
library(dplyr)
library(carData)
## We will use the dataset UN98 from the package carData.
## a) Load the package and inspect the data set
# install.packages("carData")
head(UN98)
str(UN98)
summary(UN98)
## b) create the dataset AsiaMale, containing the variables educationMale lifeMale GDPperCapita
##    economicActivityMale and illiteracyMale and the subset of Asian countries.
AsiaMale <- subset(UN98, region == "Asia", c("educationMale", "lifeMale", "GDPperCapita", "economicActivityMale", "illiteracyMale"))
## c) Let's say you're interested in whether there is a linear relationship between
## illiteracy percentage and life expectancy of males in the different countries.
## Take a look at the relationship between the two variables by
## means of a scatterplot (use the ggplot library for this).
ggplot(AsiaMale, aes(illiteracyMale,lifeMale)) + geom_point()
## e) Get the correlations between all variables in the data set using cor().
## Tell R to only include complete pairs of observations.
cor(AsiaMale, use = "pairwise.complete.obs")
## h) Calculate the Spearman rank correlation between life expectancy and GDPperCapita and compare
## it to the pearson correlation calculated above.
cor.test(AsiaMale$GDPperCapita, AsiaMale$lifeMale, method = "spearman")
## g) Is the correlation between life expectancy and GDPperCapita significant? Use cor.test()
cor.test(AsiaMale$GDPperCapita, AsiaMale$lifeMale)
## We will use the same dataset as above, but first scale the GDP to be in the unit of
## thousand dollars
AsiaMale$GDPt = AsiaMale$GDPperCapita/1000
GDPLife <- lm(lifeMale ~ GDPt, data = AsiaMale)
## b) Interpret the model from a. What do intercept and the coefficient of GDPt tell you?
summary(GDPLife)
## d) Now let's turn to the relationship between life expectancy and illiteracy.  Run the regression and
# interpret.
IlliLife <- lm(lifeMale ~ illiteracyMale, data = AsiaMale)
summary(IlliLife)
## a) Run a multiple regression model with illiteracyMale and GDPt as predictors
## General form:
## "modelname <- lm(outcome ~ predictor1+predictor2+.., data = dataFrame, na.action = an action)"
## "summary(modelname)"
GDPIlliLife <- lm(lifeMale ~ illiteracyMale + GDPt, data = AsiaMale, na.action = na.omit)
## b) Interpret the model: what do intercept and the 2 coefficients tell you? What about significance?
summary(GDPIlliLife)
# The following line of code clears your workspace:
rm(list = ls())
library(rstudioapi)
# Set the path to source file location:
setwd(dirname(getActiveDocumentContext()$path))
packages.install("rstudioapi")
install.packages("rstudioapi")
library(rstudioapi)
# Set the path to source file location:
setwd(dirname(getActiveDocumentContext()$path))
require(carData)
require(dplyr)
require(lme4)
require(ggplot2)
## Look at the dataset TitanicSurvival from the carData package.
## Look at the dataset TitanicSurvival from the carData package.
## a) Build a simple logistic regression model that models the probability of survival
## Look at the dataset TitanicSurvival from the carData package.
## a) Build a simple logistic regression model that models the probability of survival
##    (binary) based on sex (categorical) and  passengerClass (categorical) without
## Look at the dataset TitanicSurvival from the carData package.
## a) Build a simple logistic regression model that models the probability of survival
##    (binary) based on sex (categorical) and  passengerClass (categorical) without
##    an interaction and store it in mSurv.
## Look at the dataset TitanicSurvival from the carData package.
## a) Build a simple logistic regression model that models the probability of survival
##    (binary) based on sex (categorical) and  passengerClass (categorical) without
##    an interaction and store it in mSurv.
##    You have to use the glm() function and specify the family correctly.
carData$TitanicSurvival
##################################################################################
## Exercise 1: Logistic regression
##################################################################################
packages.install("carData")
##################################################################################
## Exercise 1: Logistic regression
##################################################################################
install.packages("carData")
install.packages("carData")
##################################################################################
## Exercise 1: Logistic regression
##################################################################################
install.packages("carData")
install.packages("carData")
require(carData)
require(dplyr)
require(lme4)
install.packages("lme4")
require(lme4)
require(ggplot2)
## Look at the dataset TitanicSurvival from the carData package.
## a) Build a simple logistic regression model that models the probability of survival
##    (binary) based on sex (categorical) and  passengerClass (categorical) without
##    an interaction and store it in mSurv.
##    You have to use the glm() function and specify the family correctly.
carData$TitanicSurvival
## Look at the dataset TitanicSurvival from the carData package.
## a) Build a simple logistic regression model that models the probability of survival
##    (binary) based on sex (categorical) and  passengerClass (categorical) without
##    an interaction and store it in mSurv.
##    You have to use the glm() function and specify the family correctly.
TitanicSurvival
View(TitanicSurvival)
## Look at the dataset TitanicSurvival from the carData package.
## a) Build a simple logistic regression model that models the probability of survival
##    (binary) based on sex (categorical) and  passengerClass (categorical) without
##    an interaction and store it in mSurv.
##    You have to use the glm() function and specify the family correctly.
mSurv <- glm(data = TitanicSurvival, survived ~ sex + passengerClass, family = binomial)
## b) Look at the summary. What group does the intercept correspond to?
summary(mSurv)
## d) Imagine two passengers: Rose (female, 1st class passenger) and Jack (male, 3rd class passenger).
##    Calculate their expected survival on the logit scale (i.e. the scale of the model)
##    either by hand or using predict() with a new data.frame
predict(mSurv, as.data.frame(
sex = c("male", "female"),
passengerClass = c("3rd", "1st")
), type = response)
## d) Imagine two passengers: Rose (female, 1st class passenger) and Jack (male, 3rd class passenger).
##    Calculate their expected survival on the logit scale (i.e. the scale of the model)
##    either by hand or using predict() with a new data.frame
predict(mSurv, as.data.frame(
sex = c("male", "female"),
passengerClass = c("3rd", "1st")
), type = "response")
## d) Imagine two passengers: Rose (female, 1st class passenger) and Jack (male, 3rd class passenger).
##    Calculate their expected survival on the logit scale (i.e. the scale of the model)
##    either by hand or using predict() with a new data.frame
predict(mSurv, as.data.frame(
sex = c("male", "female"),
passengerClass = c("3rd", "1st")
))
## d) Imagine two passengers: Rose (female, 1st class passenger) and Jack (male, 3rd class passenger).
##    Calculate their expected survival on the logit scale (i.e. the scale of the model)
##    either by hand or using predict() with a new data.frame
predict(mSurv, data.frame(
sex = c("female", "male"),
passengerClass = c("1st", "3rd")
))
## d) Imagine two passengers: Rose (female, 1st class passenger) and Jack (male, 3rd class passenger).
##    Calculate their expected survival on the logit scale (i.e. the scale of the model)
##    either by hand or using predict() with a new data.frame
predict(mSurv, data.frame(
sex = c("female", "male"),
passengerClass = c("1st", "3rd")
), type = "response")
## a) Download the data set from cms and read it in, store it in a variable called: coffeedat
coffeedat <- read.csv(file = "coffee.csv")
View(coffeedat)
## b) Plot the number of consumed cups of coffee in three individual scatterplots
##    by sleep, mood, and temperature.
##    You can use geom_jitter() to get a nicer plot
ggplot(coffeedat, aes(sleep, coffee)) + geom_point()
ggplot(coffeedat, aes(mood, coffee)) + geom_point()
ggplot(coffeedat, aes(temperature, coffee)) + geom_point()
## c) Can you detect an obvious relationship in any of the plots?
# In temperature, most coffee is consumed between 10 - 25.
# Worse mood is related to more coffee consumption.
# Sleep, coffee graph looks almost normal
qqplot(coffeedat$sleep, coffeedat$coffee)
## d) Fit a simple linear regression model with all three predictors and store it in linmod
linmod <- lm(data = coffeedat, coffee ~ sleep + mood + temperature)
poimod <-
glm(coffee ~ sleep + mood + temperature,
family = poisson ,
data = coffeedat)
## f) Look at the two summaries of the models and write what changed?
summary(linmod)
summary(poimod)
## g) In fact, we have repeated measures in our design, so refit the model
##    including a random intercept for subject using glmer() with the correct
##    family specification and store it in mixedpoi
mixedpoi <-
glmer (coffee ~ sleep + mood + temperature
+ (1 | subj),
family = poisson,
data = coffeedat)
## h) Look at the summary and report what changed in comparison to both linmod and poimod.
summary(mixedpoi)
## i) Finally, to make it complete, also run a mixed model using the gaussian family and store it in mixedlin
mixedlin <-
glmer (coffee ~ sleep + mood + temperature
+ (1 | subj),
family = gaussian,
data = coffeedat)
## i) Finally, to make it complete, also run a mixed model using the gaussian family and store it in mixedlin
mixedlin <-
lmer (coffee ~ sleep + mood + temperature
+ (1 | subj),
data = coffeedat)
## j) Compare the AIC for all four models. Which one has the best fit?
summary(mixedlin)
## l) Finally, report on the effects of interest in light of our research hypotheses
##    specified above for the model you chose in k)
summary(mixedpoi)
